{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S-Feature Analysis\n",
    "This is an optional notebook where we will go through the steps of creating random walks using the S-path method. These can be used as a feature when learning HAS-embeddings in the HAS_entity_embeddings notebook. We will consider different implementation decisions and look at the results of using this feature for learning embeddings.\n",
    "\n",
    "*What is this feature?* --> These random walks are intended to detect structural similarity. I.e. entities with similar types of neighbors are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisite steps to run this notebook\n",
    "1. You need to run the 1_candidate_label_creation notebook before this notebook.\n",
    "2. gensim is a dependency. You can install it with `pip install --upgrade gensim`, or if you want to use Anaconda, `conda install -c conda-forge gensim`\n",
    "3. `conda install -c pytorch faiss-cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters\n",
    "\n",
    "**Embedding model parameters**   \n",
    "*type_to_profile*: Q-node denoting the type of entities you want to create embeddings for (potentially do this for all types in the dataset and get rid of this parameter)  \n",
    "*num_walks*: Number of random walks to start at each node with the S-feature walk method   \n",
    "*walk_length*: Length of random walk started at each node  \n",
    "*representation_size*: Number of latent dimensions to learn from each node  \n",
    "*window_size*: Window size of skipgram model  \n",
    "*workers*: Number of parallel processes  \n",
    "\n",
    "**File/Directory parameters**  \n",
    "*item_file*: File path for the file that contains entity to entity relationships (e.g. wikibase-item).  \n",
    "*label_file*: File path for the file that contains wikidata labels.  \n",
    "*work_dir*: same work_dir that you specified in the label creation notebook. We'll look for files created by that notebook here. Files created by this notebook will also be saved here.  \n",
    "*store_dir*: Path to folder containing the sqlite3.db file that we will use for our queries. We will reuse an existing file if there is one in this folder. Otherwise we will create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Embedding model params\n",
    "type_to_profile = \"Q5\"\n",
    "num_walks = 10\n",
    "walk_length = 10\n",
    "representation_size = 64\n",
    "window_size = 5\n",
    "workers = 32\n",
    "\n",
    "# File/Directory params\n",
    "data_dir = \"./data/wikidata_humans\"\n",
    "item_file = \"{}/claims.wikibase-item.tsv.gz\".format(data_dir)\n",
    "label_file = \"{}/labels.en.tsv.gz\".format(data_dir)\n",
    "work_dir = \"./output/wikidata_humans_v3\"\n",
    "store_dir = \"./output/wikidata_humans_v3/temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process parameters and set up variables / file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure paths are absolute\n",
    "item_file = os.path.abspath(item_file)\n",
    "label_file = os.path.abspath(label_file)\n",
    "work_dir = os.path.abspath(work_dir)\n",
    "store_dir = os.path.abspath(store_dir)\n",
    "    \n",
    "# Create directories\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "output_dir = \"{}/S_walks_analysis\".format(work_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if not os.path.exists(store_dir):\n",
    "    os.makedirs(store_dir)\n",
    "    \n",
    "walks_file = \"{}/s_walks.txt\".format(output_dir)\n",
    "\n",
    "# Setting up environment variables \n",
    "os.environ[\"TYPE\"] = type_to_profile\n",
    "os.environ['ITEM_FILE'] = item_file\n",
    "os.environ['LABEL_FILE'] = label_file\n",
    "os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(store_dir)\n",
    "os.environ['LABEL_CREATION'] = \"{}/label_creation\".format(work_dir)\n",
    "os.environ['OUT'] = output_dir\n",
    "os.environ['kgtk'] = \"kgtk\" # Need to do this for kgtk to be recognized as a command when passing it through a subprocess call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create simple embeddings for entities based on the types of their neighbors\n",
    "\n",
    "These embeddings will have $|\\tau|$ dimensions where $\\tau$ is the set of distinct types amongst entities that share an edge with entities of type $t$. Each dimension of the embeddings will correspond to a type. The embedding for an entity will be created by filling in counts of neighbors of each type and normalizing each dimension.\n",
    "\n",
    "#### 1.1 Gather list of entities of the type_to_profile along with the types of their neighbors and the counts of neighbors of those types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk query -i $ITEM_FILE -i $LABEL_CREATION/type_mapping.tsv --graph-cache $STORE \\\n",
    "-o $OUT/${TYPE}_entity_neighbor_types.tsv \\\n",
    "--match '`'\"$ITEM_FILE\"'`: (e1)-[]->(e2), type: (e1)-[]->(t1:`'\"$TYPE\"'`), type: (e2)-[]->(t2)' \\\n",
    "--return 'distinct e1 as node1, t2 as label, count(e2) as node2, printf(\"%s_%s\",e1,t2) as id' \\\n",
    "--order-by 'e1, t2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1      label      node2  id\r\n",
      "Q10000001  Q11879590  1      Q10000001_Q11879590\r\n",
      "Q10000001  Q1288568   1      Q10000001_Q1288568\r\n",
      "Q10000001  Q1306755   1      Q10000001_Q1306755\r\n",
      "Q10000001  Q1323642   1      Q10000001_Q1323642\r\n",
      "Q10000001  Q1549591   3      Q10000001_Q1549591\r\n",
      "Q10000001  Q1637706   5      Q10000001_Q1637706\r\n",
      "Q10000001  Q185145    1      Q10000001_Q185145\r\n",
      "Q10000001  Q28640     1      Q10000001_Q28640\r\n",
      "Q10000001  Q3024240   1      Q10000001_Q3024240\r\n"
     ]
    }
   ],
   "source": [
    "!head $OUT/${TYPE}_entity_neighbor_types.tsv | column -t -s $'\\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "order neighbor types by frequency of occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kgtk query -i $OUT/${TYPE}_entity_neighbor_types.tsv -i $LABEL_FILE --graph-cache $STORE \\\n",
    "-o $OUT/${TYPE}_neighbor_types_by_freq.tsv \\\n",
    "--match 'types: (ent)-[l {label:neigh_type}]->(), `'\"$LABEL_FILE\"'`: (neigh_type)-[:label]->(type_lab)' \\\n",
    "--return 'distinct neigh_type as node1, type_lab as label, count(distinct ent) as node2, neigh_type as id' \\\n",
    "--where 'type_lab.kgtk_lqstring_lang_suffix = \"en\"' \\\n",
    "--order-by 'node2 desc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1      label                                             node2    id\r\n",
      "Q55983715  'organisms known by a particular common name'@en  7958973  Q55983715\r\n",
      "Q48264     'gender identity'@en                              5959834  Q48264\r\n",
      "Q4369513   'sex of humans'@en                                5958411  Q4369513\r\n",
      "Q28640     'profession'@en                                   5059332  Q28640\r\n",
      "Q12308941  'male given name'@en                              3432358  Q12308941\r\n",
      "Q3624078   'sovereign state'@en                              3162245  Q3624078\r\n",
      "Q12737077  'occupation'@en                                   3043379  Q12737077\r\n",
      "Q6256      'country'@en                                      2941154  Q6256\r\n",
      "Q101352    'family name'@en                                  2486879  Q101352\r\n"
     ]
    }
   ],
   "source": [
    "!head $OUT/${TYPE}_neighbor_types_by_freq.tsv | column -t -s $'\\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim down neighbor types to top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -101 $OUT/${TYPE}_neighbor_types_by_freq.tsv > $OUT/${TYPE}_neighbor_types_by_freq_trimmed_100.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out less-common neighbor types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.86 s, sys: 1.27 s, total: 8.13 s\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kgtk ifexists --input-file $OUT/${TYPE}_entity_neighbor_types_trimmed.tsv --filter-file $OUT/${TYPE}_neighbor_types_by_freq_trimmed_100.tsv \\\n",
    "--output-file $OUT/${TYPE}_entity_neighbor_types_trimmed_100.tsv --input-keys label --filter-keys node1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 13.1 s, total: 1min 29s\n",
      "Wall time: 28min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!kgtk query -i $OUT/${TYPE}_entity_neighbor_types.tsv -i $OUT/${TYPE}_neighbor_types_by_freq_trimmed.tsv --graph-cache $STORE \\\n",
    "-o $OUT/${TYPE}_entity_neighbor_types_trimmed_query.tsv \\\n",
    "--match 'entity: (ent)-[l {label:neigh_type}]->(count_neigh_type), freq: (neigh_type)-[]->()' \\\n",
    "--return 'distinct ent as node1, neigh_type as label, count_neigh_type as node2, l as id' \\\n",
    "--order-by 'node1, node2 desc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85909406\r\n"
     ]
    }
   ],
   "source": [
    "!cat $OUT/${TYPE}_entity_neighbor_types.tsv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82669563\r\n"
     ]
    }
   ],
   "source": [
    "!cat $OUT/${TYPE}_entity_neighbor_types_trimmed.tsv | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71446433\r\n"
     ]
    }
   ],
   "source": [
    "!cat $OUT/${TYPE}_entity_neighbor_types_trimmed_100.tsv | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded entity neighbor type counts\n",
      "filling in embeddings...\n",
      "CPU times: user 2min 40s, sys: 19.9 s, total: 3min\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neigh_types_df = pd.read_csv(\"{}/{}_entity_neighbor_types_trimmed_100.tsv\".format(output_dir, type_to_profile), delimiter = '\\t').fillna(\"\")\n",
    "print(\"loaded entity neighbor type counts\")\n",
    "\n",
    "neigh_types = neigh_types_df.label.unique()\n",
    "entities = neigh_types_df.node1.unique()\n",
    "neigh_type_to_idx = {neigh_types[ix] : ix for ix in range(len(neigh_types))}\n",
    "ent_to_idx = {entities[ix] : ix for ix in range(len(entities))}\n",
    "embeddings = np.zeros((len(entities),len(neigh_type_to_idx)), dtype=np.float32)\n",
    "\n",
    "print(\"filling in embeddings...\")\n",
    "for ent, neigh_type, count in zip(neigh_types_df['node1'], neigh_types_df['label'], neigh_types_df['node2']):\n",
    "    embeddings[ent_to_idx[ent], neigh_type_to_idx[neigh_type]] = count\n",
    "\n",
    "# normalize each dimension\n",
    "# embeddings -= np.nanmin(embeddings,0)\n",
    "# embeddings /= [m if m != 0 else 1 for m in np.nanmax(embeddings,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48min 38s, sys: 3min 14s, total: 51min 53s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim = embeddings.shape[-1]\n",
    "nlist = int(np.sqrt(embeddings.shape[0]))\n",
    "quantizer = faiss.IndexFlatL2(dim)\n",
    "index = faiss.IndexIVFFlat(quantizer, dim, nlist)\n",
    "assert not index.is_trained\n",
    "index.train(embeddings)\n",
    "assert index.is_trained\n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.47 s, total: 2.47 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%time faiss.write_index(index, \"{}/{}_IVFFlat_100.index\".format(output_dir, type_to_profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 nmklein div22 3.1G Apr 13 14:34 /data/profiling/kgtk/entity_profiling/output/wikidata_humans_v3/S_walks_analysis/Q5_IVFFlat_100.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh $OUT/${TYPE}_IVFFlat_100.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "closest neighbors to Putin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0. 257. 379. 392. 398. 402. 406. 425. 431. 438. 439. 442. 450. 451.\n",
      "  456. 458. 459. 461. 463. 466. 467.]]\n",
      "['Q7747', 'Q855', 'Q1394', 'Q36740', 'Q694826', 'Q458702', 'Q23505', 'Q48990', 'Q76', 'Q107441', 'Q567', 'Q454925', 'Q79822', 'Q61064', 'Q6294', 'Q1030228', 'Q83552', 'Q93031', 'Q33391', 'Q135481', 'Q7604']\n",
      "CPU times: user 634 ms, sys: 40.7 ms, total: 675 ms\n",
      "Wall time: 27.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index.nprobe = 20\n",
    "distances, neighbors = index.search(embeddings[[ent_to_idx[\"Q7747\"]]],21)\n",
    "neighbors = [entities[n] for n in neighbors[0]]\n",
    "print(distances)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing run-time with varied number of search nodes, neighbors to find, nprobe value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 513 ms, sys: 49.9 ms, total: 563 ms\n",
      "Wall time: 23.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_nodes = list(range(1))\n",
    "distances, neighbors = index.search(embeddings[start_nodes],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 s, sys: 446 ms, total: 4.15 s\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_nodes = list(range(10))\n",
    "distances, neighbors = index.search(embeddings[start_nodes],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.14 s, sys: 1.74 s, total: 9.88 s\n",
      "Wall time: 515 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_nodes = list(range(100))\n",
    "distances, neighbors = index.search(embeddings[start_nodes],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.9 s, sys: 5.51 s, total: 46.4 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_nodes = list(range(1000))\n",
    "distances, neighbors = index.search(embeddings[start_nodes],51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 58s, sys: 3.17 s, total: 9min 2s\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_nodes = list(range(10000))\n",
    "distances, neighbors = index.search(embeddings[start_nodes],21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 12s, sys: 5.06 s, total: 10min 17s\n",
      "Wall time: 30.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    distances, neighbors = index.search(embeddings[list(range(i*1000,(i+1)*1000))],21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 5s, sys: 7.8 s, total: 11min 13s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(20):\n",
    "    distances, neighbors = index.search(embeddings[list(range(i*500,(i+1)*500))],21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 7167/7959 [3:06:51<20:55,  1.58s/it]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "entity_to_neighs = dict()\n",
    "\n",
    "index.nprobe = 20\n",
    "k = 21 # number of nearest neighbors to find for each entity (including itself)\n",
    "batch_size = 1000\n",
    "num_batches = math.ceil(len(embeddings) / batch_size)\n",
    "for i in tqdm(range(num_batches)):\n",
    "    begin = i * batch_size\n",
    "    end = min((i+1)*batch_size, len(embeddings))\n",
    "    search_idxs = list(range(begin,end))\n",
    "    distances, neighbors = index.search(embeddings[search_idxs],k)\n",
    "    for j in range(len(search_idxs)):\n",
    "        ent_idx = search_idxs[j]\n",
    "        ent = entities[ent_idx]\n",
    "        nbrs = [entities[nbr_idx] for nbr_idx in neighbors[j] if nbr_idx != ent_idx]\n",
    "        entity_to_neighs[ent] = nbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/{}_entity_to_neighs_dict.json\".format(output_dir, type_to_profile), 'w') as f:\n",
    "    json.dump(entity_to_neighs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform the random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walks_to_file(entity_to_neighs, walks_file, walk_length=10, num_walks=10):\n",
    "    entities = entity_to_neighs.keys()\n",
    "    print(\"num entities to perform walks from: {}\".format(len(entities)))\n",
    "    with open(walks_file, \"w\") as f:\n",
    "        for ent in tqdm(entities):\n",
    "            for i in range(num_walks):\n",
    "                walk = random_walk_from_node(entity_to_neighs, ent, walk_length)\n",
    "                f.write(\"{}\\n\".format(walk))\n",
    "\n",
    "\n",
    "# Returns a string of space separated Q-nodes as a walk\n",
    "def random_walk_from_node(entity_to_neighs, start_ent, walk_length):\n",
    "    walk = start_ent\n",
    "    cur_ent = start_ent\n",
    "    cur_length = 1\n",
    "    while cur_length < walk_length:\n",
    "        next_ent = random.choice(entity_to_neighs[cur_ent])\n",
    "        walk = \"{} {}\".format(walk, next_ent)\n",
    "        cur_ent = next_ent\n",
    "        cur_length += 1\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num entities to perform walks from: 7958973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8c094e2fd947ac86bb02420df3e4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=7958973.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 10min 57s, sys: 22.1 s, total: 11min 19s\n",
      "Wall time: 11min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_walks_to_file(entity_to_neighs, walks_file, walk_length, num_walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Let's see what embeddings we learn if we only use this feature\n",
    "Use Skip-Gram model to learn representations for the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Word2Vec(corpus_file=walks_file, size=representation_size, window=window_size, min_count=0, sg=1, hs=1,\n",
    "                 workers=workers)\n",
    "model.wv.save(\"{}/S_embeddings.kv\".format(output_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want similar entities to have more similar embeddings. This feature aims to capture a measure of structural similarity amongst entities of the same type. Therefore we will compare entities within a type to evaluate the embeddings that are learned with this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
