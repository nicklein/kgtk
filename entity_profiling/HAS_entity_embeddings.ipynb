{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating HAS-model embeddings for entities in a KG\n",
    "The purpose of these will be for assessing entities' similarities to one another. This measure of similarity between entities will in turn be used to assess the distinctiveness of labels that have previously been created and filtered for this KG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "#from gensim.models import Word2Vec\n",
    "import graph_tool.all as gt\n",
    "from kgtk.gt.gt_load import load_graph_from_kgtk\n",
    "from kgtk.io.kgtkreader import KgtkReader\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters\n",
    "\n",
    "**Embedding model parameters**  \n",
    "*undirected*: Treat graph as undirected  \n",
    "*number_walks*: Number of random walks to start at each node  \n",
    "*walk_length*: Length of random walk started at each node  \n",
    "*seed*: Seed for random walk generator\n",
    "*representation_size*: Number of latent dimensions to learn from each node  \n",
    "*window_size*: Window size of skipgram model  \n",
    "*workers*: Number of parallel processes  \n",
    "\n",
    "**File/Directory parameters**  \n",
    "*output_filename*: Name for output representation file.  \n",
    "*item_file*: File path for the file that contains entity to entity relationships (e.g. wikibase-item).  \n",
    "*label_file*: File path for the file that contains wikidata labels.  \n",
    "*work_dir*: Path to work_dir that was specified in candidate_label_creation notebook. This should contain a folder called label_creation that has a type_mapping.tsv file within it.  \n",
    "*store_dir*: Path to folder containing the sqlite3.db file that we will use for our queries. We will reuse an existing file if there is one in this folder. Otherwise we will create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model params\n",
    "undirected = True\n",
    "number_walks = 10\n",
    "walk_length = 10\n",
    "seed = 0\n",
    "representation_size = 64\n",
    "window_size = 5\n",
    "workers = 32\n",
    "\n",
    "# File/Directory params\n",
    "output_filename = \"HAS_vec\"\n",
    "item_file = \"../../Q44/data/Q44.part.wikibase-item.tsv\"\n",
    "label_file = \"../../Q44/data/Q44.label.en.tsv\"\n",
    "work_dir = \"../../Q44/profiler_work_string_and_untrimmed_quantity\"\n",
    "store_dir = \"../../Q44\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process parameters and set up variables / file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure paths are absolute\n",
    "item_file = os.path.abspath(item_file)\n",
    "label_file = os.path.abspath(label_file)\n",
    "work_dir = os.path.abspath(work_dir)\n",
    "store_dir = os.path.abspath(store_dir)\n",
    "    \n",
    "# Create directories\n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "output_dir = \"{}/HAS_embeddings\".format(work_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "output_file = \"{}/{}\".format(output_dir, output_filename)\n",
    "\n",
    "# Setting up environment variables \n",
    "os.environ['ITEM_FILE'] = item_file\n",
    "os.environ['LABEL_FILE'] = label_file\n",
    "os.environ['STORE'] = \"{}/wikidata.sqlite3.db\".format(store_dir)\n",
    "os.environ['OUT'] = output_dir\n",
    "os.environ['WORK'] = work_dir\n",
    "os.environ['kgtk'] = \"kgtk\" # Need to do this for kgtk to be recognized as a command when passing it through a subprocess call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. H-Paths\n",
    "These random walks are intended to detect similarity due to homophily. Random walks are performed in a DFS manner\n",
    "\n",
    "#### 1.1 H-Paths - loading entity to entity edges into a Graph-Tool graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kr = KgtkReader.open(pathlib.Path(item_file))\n",
    "g = load_graph_from_kgtk(kr, directed=True, hashed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 H-Paths - Build corpus of random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs a random walk from each start node given\n",
    "# Returns a 2d array where each row is a walk made up of vertex indexes\n",
    "def random_walk(g, start_nodes, walk_length=10):\n",
    "    # pre-allocate walks array with initial values of -1\n",
    "    walks = np.ones((len(start_nodes),walk_length), dtype=int) * -1\n",
    "    \n",
    "    walks[:,0] = start_nodes\n",
    "    cur_length = 1\n",
    "    while cur_length < walk_length:\n",
    "        cur_nodes = walks[:,cur_length - 1]\n",
    "        # if we've previously hit a dead end, then we could have -1 as a \n",
    "        # current node value in this case, we want to continue filling in -1.\n",
    "        neighbors = [np.array([-1]) if v < 0 else g.get_out_neighbors(v) for v in cur_nodes]\n",
    "        # if there are no outbound edges we can take for \n",
    "        # some vertex, we'll make the next vertex we visit = -1\n",
    "        neighbors = [np.arrray([-1]) if len(arr) < 0 else arr for arr in neighbors]\n",
    "        next_nodes = [np.random.choice(arr) for arr in neighbors]\n",
    "        walks[:,cur_length] = next_nodes\n",
    "        cur_length += 1\n",
    "    # trim -1's from any walks that reached a dead end\n",
    "    walks = [arr[arr >= 0] for arr in walks]\n",
    "    return walks\n",
    "\n",
    "# Performs num_walks random walks at each node in the graph\n",
    "# i.e. if there are 10 nodes in the gaph and num_walks=10, then we'll do 10*10 = 100 random walks.\n",
    "# Returns a list of walks\n",
    "def build_corpus(g, walk_length=10, num_walks=10):\n",
    "    start_nodes = np.repeat(g.get_vertices(), num_walks)\n",
    "    walks_by_index = random_walk(g, start_nodes)\n",
    "    walks_by_qnode = [[g.vp.name[v_ix] for v_ix in walk] for walk in walks_by_index]\n",
    "    return walks_by_qnode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-dda975500da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwalks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-1a322c1657fb>\u001b[0m in \u001b[0;36mbuild_corpus\u001b[0;34m(g, walk_length, num_walks)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mstart_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vertices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mwalks_by_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_walk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mwalks_by_qnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv_ix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv_ix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwalk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalks_by_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwalks_by_qnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-1a322c1657fb>\u001b[0m in \u001b[0;36mrandom_walk\u001b[0;34m(g, start_nodes, walk_length)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# some vertex, we'll make the next vertex we visit = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnext_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwalks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcur_length\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-1a322c1657fb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# some vertex, we'll make the next vertex we visit = -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mnext_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mwalks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcur_length\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcur_length\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "walks = build_corpus(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A-Paths (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. S-Paths (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use Skip-Gram model on the combined set of random walks to learn representations for the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(walks, size=representation_size, window=window_size, min_count=0, sg=1, hs=1,\n",
    "                 workers=workers)\n",
    "model.wv.save_word2vec_format(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kgtk-env] *",
   "language": "python",
   "name": "conda-env-kgtk-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
